{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jsXIZ41dLUF0",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# CELL 1\n",
    "pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
    "pip install transformers==4.36.0 datasets scikit-learn matplotlib seaborn tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-11-17T13:50:40.945449Z",
     "iopub.status.busy": "2025-11-17T13:50:40.944717Z",
     "iopub.status.idle": "2025-11-17T13:50:43.646738Z",
     "shell.execute_reply": "2025-11-17T13:50:43.645865Z",
     "shell.execute_reply.started": "2025-11-17T13:50:40.945414Z"
    },
    "id": "krrwzUgWAAY_",
    "outputId": "5188b8b5-c435-4eaf-957f-84518da0190a",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Random seed set to 42\n",
      "============================================================\n",
      "KAGGLE GPU CHECK\n",
      "============================================================\n",
      "CUDA available: True\n",
      "GPU: Tesla T4\n",
      "GPU Memory: 14.7 GB\n",
      "\n",
      "Loading XLM-RoBERTa tokenizer...\n",
      "✓ Tokenizer loaded successfully!\n",
      "✓ All warnings suppressed!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# CELL 2: Setup and GPU Check (Kaggle Optimized)\n",
    "\n",
    "import os\n",
    "import warnings\n",
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "# Kaggle-specific: Suppress all warnings\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'\n",
    "os.environ['PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION'] = 'python'\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# SET RANDOM SEED FOR REPRODUCIBILITY\n",
    "def set_seed(seed=42):\n",
    "    \"\"\"Set all random seeds for reproducibility.\"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    print(f\"✓ Random seed set to {seed}\")\n",
    "\n",
    "# Set seed immediately\n",
    "set_seed(42)\n",
    "# Verify Kaggle GPU\n",
    "import torch\n",
    "print(\"=\"*60)\n",
    "print(\"KAGGLE GPU CHECK\")\n",
    "print(\"=\"*60)\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
    "else:\n",
    "    print(\" WARNING: No GPU detected!\")\n",
    "    print(\" Go to Settings → Accelerator → GPU (P100 or T4)\")\n",
    "\n",
    "# Load tokenizer\n",
    "from transformers import XLMRobertaTokenizer\n",
    "print(\"\\nLoading XLM-RoBERTa tokenizer...\")\n",
    "tokenizer = XLMRobertaTokenizer.from_pretrained(\"xlm-roberta-base\")\n",
    "print(\"✓ Tokenizer loaded successfully!\")\n",
    "print(\"✓ All warnings suppressed!\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T13:50:46.803426Z",
     "iopub.status.busy": "2025-11-17T13:50:46.803090Z",
     "iopub.status.idle": "2025-11-17T13:50:52.806425Z",
     "shell.execute_reply": "2025-11-17T13:50:52.805590Z",
     "shell.execute_reply.started": "2025-11-17T13:50:46.803403Z"
    },
    "id": "UltMN16_AAZM",
    "outputId": "f150393b-823e-4e3c-f444-0b85e0804d62",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1763387447.550940     178 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1763387447.556232     178 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ PyTorch: 2.6.0+cu124\n",
      "✓ Transformers: 4.53.3\n",
      "✓ CUDA: True\n",
      "✓ ALL READY!\n"
     ]
    }
   ],
   "source": [
    "# CELL 2: Import Everything\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "import os\n",
    "import transformers\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "from transformers import AutoTokenizer, XLMRobertaModel, get_linear_schedule_with_warmup\n",
    "from torch.optim import AdamW  # ← Import from torch.optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(f\"✓ PyTorch: {torch.__version__}\")\n",
    "print(f\"✓ Transformers: {transformers.__version__}\")\n",
    "print(f\"✓ CUDA: {torch.cuda.is_available()}\")\n",
    "print(\"✓ ALL READY!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ====================\n",
    "# CELL 4: Load and Augment Data (Optimized for Your Distribution)\n",
    "# ====================\n",
    "import random\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"LOADING AND AUGMENTING MULTILINGUAL DATA\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\n Loading training data...\")\n",
    "eng_train = pd.read_csv('/kaggle/input/dataset/eng_train.csv', encoding='utf-8')\n",
    "spa_train = pd.read_csv('/kaggle/input/dataset/spa_train.csv', encoding='utf-8')\n",
    "deu_train = pd.read_csv('/kaggle/input/dataset/deu_train.csv', encoding='utf-8')\n",
    "\n",
    "print(f\"  English: {len(eng_train)} samples (Ratio: 1.667:1 )\")\n",
    "print(f\"  Spanish: {len(spa_train)} samples (Ratio: 0.992:1 )\")\n",
    "print(f\"  German: {len(deu_train)} samples (Ratio: 1.103:1 )\")\n",
    "\n",
    "# ============================================\n",
    "# AUGMENT ENGLISH POLARIZED DATA (HEAVY)\n",
    "# ============================================\n",
    "print(\"\\n Augmenting English polarized data (TARGET: ~530 samples)...\")\n",
    "print(\"   Reason: English has severe imbalance (62.5% vs 37.5%)\")\n",
    "\n",
    "polarized_eng = eng_train[eng_train['polarization'] == 1].copy()\n",
    "print(f\"   Original English polarized: {len(polarized_eng)} samples\")\n",
    "print(f\"   Target after augmentation: ~1,335 samples\")\n",
    "\n",
    "augmented_eng = []\n",
    "target_augmentation = 534  # To balance English\n",
    "\n",
    "# More aggressive augmentation techniques\n",
    "for idx, row in polarized_eng.iterrows():\n",
    "    text = row['text']\n",
    "    words = text.split()\n",
    "    \n",
    "    if len(words) < 3:\n",
    "        continue\n",
    "    \n",
    "    # Technique 1: Add emphasis words (40% chance)\n",
    "    if random.random() < 0.4 and len(augmented_eng) < target_augmentation:\n",
    "        emphasis_words = ['really', 'very', 'extremely', 'absolutely', 'totally', \n",
    "                          'completely', 'clearly', 'obviously', 'definitely']\n",
    "        emphasis = random.choice(emphasis_words)\n",
    "        insert_pos = random.randint(1, min(4, len(words)-1))\n",
    "        words_copy = words.copy()\n",
    "        words_copy.insert(insert_pos, emphasis)\n",
    "        augmented_eng.append({\n",
    "            'text': ' '.join(words_copy),\n",
    "            'polarization': 1\n",
    "        })\n",
    "    \n",
    "    # Technique 2: Synonym replacement for common words (30% chance)\n",
    "    if random.random() < 0.3 and len(augmented_eng) < target_augmentation:\n",
    "        synonyms = {\n",
    "            'bad': ['terrible', 'awful', 'horrible'],\n",
    "            'good': ['great', 'excellent', 'wonderful'],\n",
    "            'hate': ['despise', 'detest', 'loathe'],\n",
    "            'love': ['adore', 'cherish', 'treasure'],\n",
    "            'stupid': ['foolish', 'idiotic', 'moronic'],\n",
    "            'smart': ['intelligent', 'clever', 'bright']\n",
    "        }\n",
    "        words_copy = words.copy()\n",
    "        for i, word in enumerate(words_copy):\n",
    "            word_lower = word.lower()\n",
    "            if word_lower in synonyms and random.random() < 0.5:\n",
    "                words_copy[i] = random.choice(synonyms[word_lower])\n",
    "                break\n",
    "        \n",
    "        augmented_text = ' '.join(words_copy)\n",
    "        if augmented_text != text:  \n",
    "            augmented_eng.append({\n",
    "                'text': augmented_text,\n",
    "                'polarization': 1\n",
    "            })\n",
    "    \n",
    "    # Technique 3: Word swap (25% chance)\n",
    "    if random.random() < 0.25 and len(words) > 4 and len(augmented_eng) < target_augmentation:\n",
    "        words_copy = words.copy()\n",
    "        swap_pos = random.randint(1, len(words_copy)-3)\n",
    "        \n",
    "        skip_words = ['the', 'a', 'an', 'is', 'are', 'was', 'were', 'be', \n",
    "                      'of', 'to', 'in', 'for', 'on', 'at', 'by', 'with']\n",
    "        \n",
    "        if (words_copy[swap_pos].lower() not in skip_words and \n",
    "            words_copy[swap_pos+1].lower() not in skip_words):\n",
    "            words_copy[swap_pos], words_copy[swap_pos+1] = words_copy[swap_pos+1], words_copy[swap_pos]\n",
    "            augmented_eng.append({\n",
    "                'text': ' '.join(words_copy),\n",
    "                'polarization': 1\n",
    "            })\n",
    "    \n",
    "    # Technique 4: Duplicate with minor variation (20% chance)\n",
    "    if random.random() < 0.2 and len(augmented_eng) < target_augmentation:\n",
    "        words_copy = words.copy()\n",
    "        # Add a filler word at the beginning\n",
    "        fillers = ['Well,', 'So,', 'Actually,', 'Honestly,', 'Basically,']\n",
    "        words_copy.insert(0, random.choice(fillers))\n",
    "        augmented_eng.append({\n",
    "            'text': ' '.join(words_copy),\n",
    "            'polarization': 1\n",
    "        })\n",
    "    \n",
    "    # Stop if we've reached our target\n",
    "    if len(augmented_eng) >= target_augmentation:\n",
    "        break\n",
    "\n",
    "# Add augmented data to English training set\n",
    "if augmented_eng:\n",
    "    augmented_df = pd.DataFrame(augmented_eng)\n",
    "    eng_train = pd.concat([eng_train, augmented_df], ignore_index=True)\n",
    "    \n",
    "    # Check new balance\n",
    "    eng_pol_counts = eng_train['polarization'].value_counts().sort_index()\n",
    "    new_eng_ratio = eng_pol_counts[0] / eng_pol_counts[1]\n",
    "    \n",
    "    print(f\"\\n    Added {len(augmented_eng)} augmented English samples\")\n",
    "    print(f\"   New English distribution:\")\n",
    "    print(f\"      Non-Polarized: {eng_pol_counts[0]}\")\n",
    "    print(f\"      Polarized: {eng_pol_counts[1]}\")\n",
    "    print(f\"      New ratio: {new_eng_ratio:.3f}:1 {'✅' if new_eng_ratio < 1.1 else '⚠️'}\")\n",
    "else:\n",
    "    print(f\"   No augmentation performed\")\n",
    "\n",
    "# ============================================\n",
    "# OPTIONAL: LIGHT GERMAN AUGMENTATION\n",
    "# ============================================\n",
    "print(\"\\n German augmentation (light - optional)...\")\n",
    "print(\"   German is already well-balanced (1.103:1), adding just ~50 samples\")\n",
    "\n",
    "polarized_deu = deu_train[deu_train['polarization'] == 1].copy()\n",
    "augmented_deu = []\n",
    "target_deu = 50\n",
    "\n",
    "for idx, row in polarized_deu.iterrows():\n",
    "    text = row['text']\n",
    "    words = text.split()\n",
    "    \n",
    "    if len(words) > 4 and random.random() < 0.3 and len(augmented_deu) < target_deu:\n",
    "        # Add German emphasis words\n",
    "        emphasis = random.choice(['sehr', 'wirklich', 'extrem', 'absolut', 'total', 'völlig'])\n",
    "        insert_pos = random.randint(1, min(3, len(words)-1))\n",
    "        words_copy = words.copy()\n",
    "        words_copy.insert(insert_pos, emphasis)\n",
    "        augmented_deu.append({\n",
    "            'text': ' '.join(words_copy),\n",
    "            'polarization': 1\n",
    "        })\n",
    "    \n",
    "    if len(augmented_deu) >= target_deu:\n",
    "        break\n",
    "\n",
    "if augmented_deu:\n",
    "    deu_train = pd.concat([deu_train, pd.DataFrame(augmented_deu)], ignore_index=True)\n",
    "    print(f\"    Added {len(augmented_deu)} augmented German samples\")\n",
    "else:\n",
    "    print(f\"    Skipped German augmentation (already balanced)\")\n",
    "\n",
    "print(\"\\n Spanish augmentation: SKIPPED\")\n",
    "print(\"   Spanish is perfectly balanced (0.992:1) - no augmentation needed!\")\n",
    "\n",
    "# ============================================\n",
    "# ADD LANGUAGE LABELS\n",
    "# ============================================\n",
    "eng_train['language'] = 'en'\n",
    "spa_train['language'] = 'es'\n",
    "deu_train['language'] = 'de'\n",
    "\n",
    "print(\"\\n Combining training data...\")\n",
    "train_df = pd.concat([eng_train, spa_train, deu_train], ignore_index=True)\n",
    "train_df = train_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\" FINAL TRAINING DATA STATISTICS (AFTER AUGMENTATION)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "total_samples = len(train_df)\n",
    "pol_counts = train_df['polarization'].value_counts().sort_index()\n",
    "final_ratio = pol_counts[0] / pol_counts[1]\n",
    "\n",
    "print(f\"\\n  Total samples: {total_samples:,}\")\n",
    "print(f\"  Non-Polarized (0): {pol_counts[0]:,} ({pol_counts[0]/total_samples*100:.1f}%)\")\n",
    "print(f\"  Polarized (1): {pol_counts[1]:,} ({pol_counts[1]/total_samples*100:.1f}%)\")\n",
    "print(f\"  Final ratio: {final_ratio:.3f}:1\")\n",
    "\n",
    "if final_ratio < 1.05:\n",
    "    balance_status = \" EXCELLENT - Nearly Perfect!\"\n",
    "    weight_recommendation = \"NO class weights needed\"\n",
    "elif final_ratio < 1.10:\n",
    "    balance_status = \" VERY GOOD - Well Balanced\"\n",
    "    weight_recommendation = \"Use NO weights OR very light [1.0, 1.03]\"\n",
    "elif final_ratio < 1.15:\n",
    "    balance_status = \" GOOD - Acceptable Balance\"\n",
    "    weight_recommendation = \"Use light weights [1.0, 1.05]\"\n",
    "else:\n",
    "    balance_status = \" MODERATE - Some Imbalance Remains\"\n",
    "    weight_recommendation = \"Use moderate weights [1.0, 1.10]\"\n",
    "\n",
    "print(f\"\\n  Balance Status: {balance_status}\")\n",
    "print(f\"   Recommendation: {weight_recommendation}\")\n",
    "\n",
    "# Language breakdown\n",
    "print(f\"\\n  By Language:\")\n",
    "for lang, lang_name in [('en', 'English'), ('es', 'Spanish'), ('de', 'German')]:\n",
    "    lang_df = train_df[train_df['language'] == lang]\n",
    "    lang_pol = lang_df['polarization'].value_counts().sort_index()\n",
    "    lang_ratio = lang_pol[0] / lang_pol[1] if lang_pol[1] > 0 else 0\n",
    "    print(f\"    {lang_name}: {len(lang_df):,} samples (Ratio: {lang_ratio:.3f}:1)\")\n",
    "\n",
    "print(\"\\n Loading test data...\")\n",
    "eng_test = pd.read_csv('/kaggle/input/dataset/eng_test.csv', encoding='utf-8')\n",
    "spa_test = pd.read_csv('/kaggle/input/dataset/spa_test.csv', encoding='utf-8')\n",
    "deu_test = pd.read_csv('/kaggle/input/dataset/deu_test.csv', encoding='utf-8')\n",
    "\n",
    "eng_test['language'] = 'en'\n",
    "spa_test['language'] = 'es'\n",
    "deu_test['language'] = 'de'\n",
    "\n",
    "test_df = pd.concat([eng_test, spa_test, deu_test], ignore_index=True)\n",
    "\n",
    "print(f\"  Total test samples: {len(test_df):,}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\" DATA LOADING AND AUGMENTATION COMPLETE!\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\n Augmentation Summary:\")\n",
    "print(f\"  • English: +{len(augmented_eng)} samples (balanced severe imbalance)\")\n",
    "print(f\"  • Spanish: +0 samples (already perfect)\")\n",
    "print(f\"  • German: +{len(augmented_deu) if augmented_deu else 0} samples (light touch-up)\")\n",
    "print(f\"  • Total added: {len(augmented_eng) + (len(augmented_deu) if augmented_deu else 0)} samples\")\n",
    "\n",
    "print(f\"\\n Impact:\")\n",
    "print(f\"  • Before: 1.194:1 (54.4% vs 45.6%) \")\n",
    "print(f\"  • After: {final_ratio:.3f}:1 ({pol_counts[0]/total_samples*100:.1f}% vs {pol_counts[1]/total_samples*100:.1f}%) {balance_status.split()[0]}\")\n",
    "print(f\"  • Improvement: {((1.194 - final_ratio) / 1.194 * 100):.1f}% better balance!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m0MGIs9lAAZX",
    "outputId": "b01b2a29-3f7e-40e6-bcf2-fd58c816549c",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ====================\n",
    "# CELL 5: Data Inspection & Preprocessing\n",
    "# ====================\n",
    "\n",
    "TEXT_COLUMN = 'text'           \n",
    "LABEL_COLUMN = 'polarization' \n",
    "\n",
    "print(\"Dataset Information:\")\n",
    "print(f\"Text column: '{TEXT_COLUMN}'\")\n",
    "print(f\"Label column: '{LABEL_COLUMN}'\")\n",
    "print(f\"Task: Binary polarized Speech Detection (Polarization)\")\n",
    "print(f\"  0 = Non-polarized speech\")\n",
    "print(f\"  1 = polarized speech / Negative polarization\")\n",
    "\n",
    "# Check for missing values\n",
    "print(f\"\\nMissing values in training data:\")\n",
    "print(train_df[[TEXT_COLUMN, LABEL_COLUMN]].isnull().sum())\n",
    "\n",
    "# Check label distribution\n",
    "print(f\"\\nLabel distribution in training data:\")\n",
    "label_counts = train_df[LABEL_COLUMN].value_counts().sort_index()\n",
    "print(label_counts)\n",
    "print(f\"\\nClass breakdown:\")\n",
    "print(f\"  Class 0 (Non-polarized): {label_counts.get(0, 0)} samples ({label_counts.get(0, 0)/len(train_df)*100:.1f}%)\")\n",
    "print(f\"  Class 1 (polarized speech): {label_counts.get(1, 0)} samples ({label_counts.get(1, 0)/len(train_df)*100:.1f}%)\")\n",
    "\n",
    "# Clean data\n",
    "def clean_data(df, text_col, label_col):\n",
    "    \"\"\"Basic data cleaning.\"\"\"\n",
    "    initial_size = len(df)\n",
    "\n",
    "    # Remove missing values\n",
    "    df = df.dropna(subset=[text_col, label_col])\n",
    "\n",
    "    # Remove empty strings\n",
    "    df = df[df[text_col].str.strip() != '']\n",
    "\n",
    "    # Remove duplicates\n",
    "    df = df.drop_duplicates(subset=[text_col])\n",
    "\n",
    "    # Reset index\n",
    "    df = df.reset_index(drop=True)\n",
    "\n",
    "    print(f\"Cleaned: {initial_size} → {len(df)} samples\")\n",
    "    return df\n",
    "\n",
    "train_df = clean_data(train_df, TEXT_COLUMN, LABEL_COLUMN)\n",
    "test_df = clean_data(test_df, TEXT_COLUMN, LABEL_COLUMN)\n",
    "\n",
    "# Create validation set from training data (10%)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, val_df = train_test_split(\n",
    "    train_df,\n",
    "    test_size=0.1,\n",
    "    random_state=42,\n",
    "    stratify=train_df[LABEL_COLUMN]\n",
    ")\n",
    "\n",
    "print(f\"\\nFinal data splits:\")\n",
    "print(f\"  Train: {len(train_df)} samples\")\n",
    "print(f\"  Val:   {len(val_df)} samples\")\n",
    "print(f\"  Test:  {len(test_df)} samples\")\n",
    "\n",
    "# Get number of classes\n",
    "num_classes = len(train_df[LABEL_COLUMN].unique())\n",
    "print(f\"\\nNumber of classes: {num_classes}\")\n",
    "print(f\"Classes: {sorted(train_df[LABEL_COLUMN].unique())}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qBNjM8nyAAZZ",
    "outputId": "231d8de1-6e2f-40f7-b783-68b62c04d56b",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ====================\n",
    "# CELL 6: Create PyTorch Dataset\n",
    "# ====================\n",
    "\n",
    "class MultilingualTextDataset(Dataset):\n",
    "    \"\"\"Dataset for XLM-RoBERTa multilingual text classification.\"\"\"\n",
    "\n",
    "    def __init__(self, texts, labels, tokenizer, max_length=512):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        # Tokenize\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            max_length=self.max_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "print(\" Dataset class defined!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T13:51:02.840036Z",
     "iopub.status.busy": "2025-11-17T13:51:02.838741Z",
     "iopub.status.idle": "2025-11-17T13:51:02.864516Z",
     "shell.execute_reply": "2025-11-17T13:51:02.863506Z",
     "shell.execute_reply.started": "2025-11-17T13:51:02.839998Z"
    },
    "id": "Y6uXMMnwAAZa",
    "outputId": "ee4ac8f2-e641-4fa6-abb1-843bcc7f7b96",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ MacroF1OptimizedModel for Polarization Detection!\n",
      "\n",
      " Model Architecture:\n",
      "   Attention pooling (captures 'us vs them' throughout text)\n",
      "   Multi-sample dropout (n=5, ensemble effect)\n",
      "   Balanced focal loss (α=0.5, γ=1.5)\n",
      "   Label smoothing (0.1, better generalization)\n"
     ]
    }
   ],
   "source": [
    "# ====================\n",
    "# CELL 7: Model Definition with Loss Functions (OPTIMIZED FOR BALANCED DATA)\n",
    "# ====================\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from transformers import XLMRobertaModel\n",
    "\n",
    "# ============================================\n",
    "# FOCAL LOSS (OPTIMIZED FOR BALANCED POLARIZATION DATA)\n",
    "# ============================================\n",
    "class ClassBalancedFocalLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Focal loss with class-specific weights\n",
    "    Optimized for balanced polarization detection (54% vs 46%)\n",
    "    \"\"\"\n",
    "    def __init__(self, alpha=None, gamma=None, class_weights=None, label_smoothing=0.1):\n",
    "        super().__init__()\n",
    "        # Default values optimized for balanced data\n",
    "        self.alpha = alpha if alpha is not None else 0.5  # Equal weight for balanced classes\n",
    "        self.gamma = gamma if gamma is not None else 1.5  # Moderate difficulty focus\n",
    "        self.class_weights = class_weights\n",
    "        self.label_smoothing = label_smoothing\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        # Apply label smoothing\n",
    "        if self.label_smoothing > 0:\n",
    "            n_classes = inputs.size(-1)\n",
    "            targets_one_hot = F.one_hot(targets, n_classes).float()\n",
    "            targets_smoothed = targets_one_hot * (1 - self.label_smoothing) + self.label_smoothing / n_classes\n",
    "            ce_loss = -(targets_smoothed * F.log_softmax(inputs, dim=-1)).sum(dim=-1)\n",
    "        else:\n",
    "            ce_loss = F.cross_entropy(inputs, targets, reduction='none')\n",
    "        \n",
    "        pt = torch.exp(-ce_loss)\n",
    "        focal_loss = self.alpha * (1 - pt) ** self.gamma * ce_loss\n",
    "\n",
    "        # Apply class weights if provided\n",
    "        if self.class_weights is not None:\n",
    "            weights = self.class_weights[targets].to(inputs.device)\n",
    "            focal_loss = focal_loss * weights\n",
    "\n",
    "        return focal_loss.mean()\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# MIXUP HELPERS\n",
    "# ============================================\n",
    "def mixup_data(x, y, alpha=0.2):\n",
    "    \"\"\"\n",
    "    Apply mixup augmentation to embeddings\n",
    "    Lighter alpha (0.2) for balanced data\n",
    "    \"\"\"\n",
    "    if alpha > 0:\n",
    "        lam = np.random.beta(alpha, alpha)\n",
    "    else:\n",
    "        lam = 1.0\n",
    "\n",
    "    batch_size = x.size(0)\n",
    "    index = torch.randperm(batch_size).to(x.device)\n",
    "\n",
    "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
    "    y_a, y_b = y, y[index]\n",
    "\n",
    "    return mixed_x, y_a, y_b, lam\n",
    "\n",
    "\n",
    "def mixup_criterion(criterion, pred, y_a, y_b, lam):\n",
    "    \"\"\"Calculate mixup loss.\"\"\"\n",
    "    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# MODEL DEFINITION (OPTIMIZED FOR POLARIZATION DETECTION)\n",
    "# ============================================\n",
    "class MacroF1OptimizedModel(nn.Module):\n",
    "    \"\"\"\n",
    "    XLM-RoBERTa optimized for Macro F1-Score on polarization detection\n",
    "    \n",
    "    Features:\n",
    "    - Multi-sample dropout ensemble (reduces overfitting)\n",
    "    - Attention pooling (better sequence representation)\n",
    "    - Class-balanced focal loss (handles slight imbalance: 54% vs 46%)\n",
    "    - Optimized for detecting \"us vs them\" polarization patterns\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_classes=2, model_name='xlm-roberta-large',\n",
    "                 dropout=0.2, num_dropouts=5, class_weights=None, \n",
    "                 focal_alpha=0.5, focal_gamma=1.5):\n",
    "        super().__init__()\n",
    "\n",
    "        self.roberta = XLMRobertaModel.from_pretrained(model_name)\n",
    "        hidden_size = self.roberta.config.hidden_size\n",
    "\n",
    "        # Attention pooling for better context understanding\n",
    "        self.attention = nn.Linear(hidden_size, 1)\n",
    "\n",
    "        # Multi-sample dropout for ensemble effect\n",
    "        self.dropouts = nn.ModuleList([\n",
    "            nn.Dropout(dropout) for _ in range(num_dropouts)\n",
    "        ])\n",
    "\n",
    "        # Classification head\n",
    "        self.classifier = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "        # Loss function optimized for balanced data\n",
    "        self.loss_fn = ClassBalancedFocalLoss(\n",
    "            alpha=focal_alpha,\n",
    "            gamma=focal_gamma,\n",
    "            class_weights=class_weights,\n",
    "            label_smoothing=0.1  # Slight smoothing for better generalization\n",
    "        )\n",
    "\n",
    "        # Initialize weights\n",
    "        nn.init.normal_(self.classifier.weight, std=0.02)\n",
    "        nn.init.zeros_(self.classifier.bias)\n",
    "\n",
    "    def attention_pooling(self, hidden_states, attention_mask):\n",
    "        \"\"\"\n",
    "        Attention-based pooling over sequence\n",
    "        Better than [CLS] token for capturing polarization markers throughout text\n",
    "        \"\"\"\n",
    "        attention_weights = self.attention(hidden_states)\n",
    "        attention_weights = attention_weights.masked_fill(\n",
    "            attention_mask.unsqueeze(-1) == 0, -1e9\n",
    "        )\n",
    "        attention_weights = F.softmax(attention_weights, dim=1)\n",
    "        pooled = torch.sum(hidden_states * attention_weights, dim=1)\n",
    "        return pooled\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, labels=None,\n",
    "                embeddings=None, mixup_params=None):\n",
    "        # Get RoBERTa outputs\n",
    "        if embeddings is not None:\n",
    "            outputs = self.roberta(inputs_embeds=embeddings, attention_mask=attention_mask)\n",
    "        else:\n",
    "            outputs = self.roberta(input_ids=input_ids, attention_mask=attention_mask)\n",
    "\n",
    "        # Attention pooling\n",
    "        pooled_output = self.attention_pooling(outputs.last_hidden_state, attention_mask)\n",
    "\n",
    "        # Multi-sample dropout ensemble (reduces variance)\n",
    "        if self.training:\n",
    "            logits_list = []\n",
    "            for dropout in self.dropouts:\n",
    "                dropped = dropout(pooled_output)\n",
    "                logits_list.append(self.classifier(dropped))\n",
    "            logits = torch.stack(logits_list).mean(dim=0)\n",
    "        else:\n",
    "            pooled_output = self.dropouts[0](pooled_output)\n",
    "            logits = self.classifier(pooled_output)\n",
    "\n",
    "        # Calculate loss\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            if mixup_params is not None:\n",
    "                y_a, y_b, lam = mixup_params\n",
    "                loss = mixup_criterion(self.loss_fn, logits, y_a, y_b, lam)\n",
    "            else:\n",
    "                loss = self.loss_fn(logits, labels)\n",
    "\n",
    "        return {\n",
    "            'loss': loss,\n",
    "            'logits': logits,\n",
    "            'pooled_output': pooled_output\n",
    "        }\n",
    "\n",
    "\n",
    "print(\"✓ MacroF1OptimizedModel for Polarization Detection!\")\n",
    "print(\"\\n Model Architecture:\")\n",
    "print(\"   Attention pooling (captures 'us vs them' throughout text)\")\n",
    "print(\"   Multi-sample dropout (n=5, ensemble effect)\")\n",
    "print(\"   Balanced focal loss (α=0.5, γ=1.5)\")\n",
    "print(\"   Label smoothing (0.1, better generalization)\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ncDYHK1pAAZc",
    "outputId": "0439483b-a2f1-40c4-b41c-569090c073e7",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ====================\n",
    "# CELL 8: Configuration and Model Setup \n",
    "# ====================\n",
    "import gc\n",
    "set_seed(42) \n",
    "# Clear GPU memory\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "# ============================================\n",
    "# CONFIGURATION \n",
    "# ============================================\n",
    "CONFIG = {\n",
    "    'model_name': 'xlm-roberta-large',  \n",
    "    'max_length': 128,\n",
    "    'batch_size': 8,\n",
    "    'num_epochs': 20,                  \n",
    "    'learning_rate': 1e-6,             \n",
    "    'weight_decay': 0.03,\n",
    "    'dropout': 0.5,                    \n",
    "    'num_dropouts': 5,\n",
    "    'gradient_accumulation_steps': 4,\n",
    "    'max_grad_norm': 1.0,\n",
    "    'warmup_steps': 1000,\n",
    "    'use_mixup': True,\n",
    "    'mixup_alpha': 0.2,\n",
    "    'use_tta': True,\n",
    "    'tta_iterations': 5,\n",
    "    'focal_alpha': 0.5,\n",
    "    'focal_gamma': 2.0,\n",
    "}\n",
    "MODEL_NAME = 'model_4_large_careful'  \n",
    "\n",
    "print(\"OPTIMIZED Configuration for XLM-RoBERTa-Large:\")\n",
    "print(\"=\"*70)\n",
    "for key, value in CONFIG.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# CREATE DATASETS AND DATALOADERS\n",
    "# ============================================\n",
    "print(\"\\nCreating datasets...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(CONFIG['model_name'])\n",
    "\n",
    "train_dataset = MultilingualTextDataset(\n",
    "    train_df[TEXT_COLUMN].tolist(),\n",
    "    train_df[LABEL_COLUMN].tolist(),\n",
    "    tokenizer,\n",
    "    CONFIG['max_length']\n",
    ")\n",
    "\n",
    "val_dataset = MultilingualTextDataset(\n",
    "    val_df[TEXT_COLUMN].tolist(),\n",
    "    val_df[LABEL_COLUMN].tolist(),\n",
    "    tokenizer,\n",
    "    CONFIG['max_length']\n",
    ")\n",
    "\n",
    "test_dataset = MultilingualTextDataset(\n",
    "    test_df[TEXT_COLUMN].tolist(),\n",
    "    test_df[LABEL_COLUMN].tolist(),\n",
    "    tokenizer,\n",
    "    CONFIG['max_length']\n",
    ")\n",
    "\n",
    "print(\"✓ Datasets created!\")\n",
    "\n",
    "# ============================================\n",
    "# CREATE DATALOADERS\n",
    "# ============================================\n",
    "print(\"\\nCreating dataloaders...\")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=CONFIG['batch_size'], \n",
    "    shuffle=True,\n",
    "    num_workers=2,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, \n",
    "    batch_size=CONFIG['batch_size'], \n",
    "    shuffle=False,\n",
    "    num_workers=2,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset, \n",
    "    batch_size=CONFIG['batch_size'], \n",
    "    shuffle=False,\n",
    "    num_workers=2,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "print(f\"\\nDataLoaders ready:\")\n",
    "print(f\"  Train batches: {len(train_loader)}\")\n",
    "print(f\"  Val batches: {len(val_loader)}\")\n",
    "print(f\"  Test batches: {len(test_loader)}\")\n",
    "\n",
    "# ============================================\n",
    "# INITIALIZE MODEL\n",
    "# ============================================\n",
    "print(\"\\nInitializing device...\")\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "# NO CLASS WEIGHTS - data is balanced\n",
    "class_weights = None\n",
    "print(f\"\\n Using NO class weights (data is balanced: 1.016:1)\")\n",
    "\n",
    "# Initialize model\n",
    "print(\"\\nInitializing XLM-RoBERTa model...\")\n",
    "model = MacroF1OptimizedModel(\n",
    "    num_classes=num_classes,\n",
    "    model_name=CONFIG['model_name'],\n",
    "    dropout=CONFIG['dropout'],\n",
    "    num_dropouts=CONFIG['num_dropouts'],\n",
    "    class_weights=class_weights,\n",
    "    focal_alpha=CONFIG['focal_alpha'],\n",
    "    focal_gamma=CONFIG['focal_gamma']\n",
    ")\n",
    "model = model.to(device)\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\" Model initialized!\")\n",
    "print(f\"  Trainable parameters: {trainable_params:,}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"\\nGPU Memory:\")\n",
    "    print(f\"  Allocated: {torch.cuda.memory_allocated(0) / 1024**3:.2f} GB\")\n",
    "    print(f\"  Reserved: {torch.cuda.memory_reserved(0) / 1024**3:.2f} GB\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pkPTcGEJAAZe",
    "outputId": "88f1b135-56a7-42df-9916-36f65f7fba52",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ====================\n",
    "# CELL 9: Training & Evaluation Functions\n",
    "# ====================\n",
    "from sklearn.metrics import f1_score, precision_recall_fscore_support\n",
    "\n",
    "# ============================================\n",
    "# TEST-TIME AUGMENTATION\n",
    "# ============================================\n",
    "def predict_with_tta(model, batch, device, n_iterations=5):\n",
    "    \"\"\"Test-time augmentation for better predictions.\"\"\"\n",
    "    model.eval()\n",
    "    all_logits = []\n",
    "\n",
    "    input_ids = batch['input_ids'].to(device)\n",
    "    attention_mask = batch['attention_mask'].to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for _ in range(n_iterations):\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            logits = outputs['logits']\n",
    "            all_logits.append(logits)\n",
    "\n",
    "    avg_logits = torch.stack(all_logits).mean(dim=0)\n",
    "    preds = torch.argmax(avg_logits, dim=1)\n",
    "    return preds, avg_logits\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# THRESHOLD OPTIMIZATION\n",
    "# ============================================\n",
    "def optimize_threshold(model, val_loader, device):\n",
    "    \"\"\"Find optimal classification threshold for Macro F1.\"\"\"\n",
    "    model.eval()\n",
    "    all_probs = []\n",
    "    all_labels = []\n",
    "\n",
    "    print(\"\\nOptimizing threshold...\")\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(val_loader, desc='Computing probabilities'):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].cpu().numpy()\n",
    "\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            logits = outputs['logits']\n",
    "            probs = F.softmax(logits, dim=1)[:, 1]\n",
    "\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "            all_labels.extend(labels)\n",
    "\n",
    "    # Try different thresholds\n",
    "    best_threshold = 0.5\n",
    "    best_macro_f1 = -1.0\n",
    "\n",
    "    for threshold in np.arange(0.3, 0.7, 0.01):\n",
    "        preds = (np.array(all_probs) >= threshold).astype(int)\n",
    "        macro_f1 = f1_score(all_labels, preds, average='macro')\n",
    "\n",
    "        if macro_f1 > best_macro_f1:\n",
    "            best_macro_f1 = macro_f1\n",
    "            best_threshold = float(threshold)\n",
    "\n",
    "    print(f\"Optimal Threshold: {best_threshold:.3f}\")\n",
    "    print(f\"Macro F1 at optimal threshold: {best_macro_f1:.4f}\")\n",
    "\n",
    "    return best_threshold\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# TRAINING FUNCTION\n",
    "# ============================================\n",
    "def train_epoch(model, data_loader, optimizer, scheduler, device):\n",
    "    \"\"\"Training loop with mixup and gradient accumulation.\"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    progress_bar = tqdm(data_loader, desc='Training')\n",
    "\n",
    "    for batch_idx, batch in enumerate(progress_bar):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        # Apply mixup randomly (50% of batches)\n",
    "        if CONFIG['use_mixup'] and np.random.rand() > 0.5:\n",
    "            with torch.no_grad():\n",
    "                embeddings = model.roberta.embeddings(input_ids=input_ids)\n",
    "            mixed_embeddings, y_a, y_b, lam = mixup_data(embeddings, labels, CONFIG['mixup_alpha'])\n",
    "\n",
    "            outputs = model(\n",
    "                input_ids=None,\n",
    "                attention_mask=attention_mask,\n",
    "                labels=labels,\n",
    "                embeddings=mixed_embeddings,\n",
    "                mixup_params=(y_a, y_b, lam)\n",
    "            )\n",
    "        else:\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "\n",
    "        loss = outputs['loss']\n",
    "        logits = outputs['logits']\n",
    "\n",
    "        # Scale loss for gradient accumulation\n",
    "        loss = loss / CONFIG['gradient_accumulation_steps']\n",
    "        loss.backward()\n",
    "\n",
    "        # Gradient accumulation step\n",
    "        if (batch_idx + 1) % CONFIG['gradient_accumulation_steps'] == 0:\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), CONFIG['max_grad_norm'])\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        # Track metrics\n",
    "        with torch.no_grad():\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "        total_loss += (loss.item() * CONFIG['gradient_accumulation_steps'])\n",
    "\n",
    "        # Update progress bar\n",
    "        if len(all_labels) > 0:\n",
    "            current_f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "            progress_bar.set_postfix({\n",
    "                'loss': f\"{(loss.item() * CONFIG['gradient_accumulation_steps']):.4f}\",\n",
    "                'macro_f1': f\"{current_f1:.4f}\"\n",
    "            })\n",
    "\n",
    "    avg_loss = total_loss / len(data_loader)\n",
    "    epoch_f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "\n",
    "    return avg_loss, epoch_f1\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# EVALUATION FUNCTION\n",
    "# ============================================\n",
    "def evaluate(model, data_loader, device, threshold=0.5, use_tta=False):\n",
    "    \"\"\"Evaluation with optional TTA and custom threshold.\"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    all_probs = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(data_loader, desc='Evaluating'):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            if use_tta and CONFIG['use_tta']:\n",
    "                preds, avg_logits = predict_with_tta(model, batch, device, CONFIG['tta_iterations'])\n",
    "                probs = F.softmax(avg_logits, dim=1)\n",
    "            else:\n",
    "                outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "                loss = outputs['loss']\n",
    "                logits = outputs['logits']\n",
    "                total_loss += loss.item()\n",
    "                probs = F.softmax(logits, dim=1)\n",
    "\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    # Apply threshold to positive-class probability\n",
    "    all_probs = np.array(all_probs)\n",
    "    all_preds = (all_probs[:, 1] >= threshold).astype(int)\n",
    "\n",
    "    # Calculate metrics\n",
    "    avg_loss = total_loss / len(data_loader) if total_loss > 0 else 0.0\n",
    "    macro_f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "    weighted_f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "\n",
    "    per_class_metrics = precision_recall_fscore_support(all_labels, all_preds, average=None)\n",
    "\n",
    "    return {\n",
    "        'loss': avg_loss,\n",
    "        'macro_f1': macro_f1,\n",
    "        'weighted_f1': weighted_f1,\n",
    "        'per_class_f1': per_class_metrics[2],\n",
    "        'predictions': all_preds,\n",
    "        'labels': all_labels\n",
    "    }\n",
    "\n",
    "print(\" Training and evaluation functions defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import torch\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "print(\" GPU memory cleared\")\n",
    "print(f\"Allocated: {torch.cuda.memory_allocated(0) / 1024**3:.2f} GB\")\n",
    "print(f\"Reserved: {torch.cuda.memory_reserved(0) / 1024**3:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8rkS3d3dAAZj",
    "outputId": "4664db2d-9d6f-41df-c3b0-01d0d1a5190e",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ====================\n",
    "# CELL 10: Optimized Training for Balanced Polarization Data\n",
    "# ====================\n",
    "\n",
    "import gc\n",
    "import os\n",
    "from torch.optim.lr_scheduler import OneCycleLR\n",
    "import copy\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "# ============================================\n",
    "# MEMORY OPTIMIZATION\n",
    "# ============================================\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "torch.backends.cudnn.allow_tf32 = True\n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:512,expandable_segments:True'\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\" Device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"  GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"  Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "# ============================================\n",
    "# LAYERWISE LEARNING RATE (OPTIMIZED FOR POLARIZATION)\n",
    "# ============================================\n",
    "def get_optimizer_grouped_parameters(model, learning_rate, weight_decay):\n",
    "    \"\"\"\n",
    "    Create parameter groups with layerwise learning rates\n",
    "    Optimized for polarization detection (needs more semantic understanding)\n",
    "    \"\"\"\n",
    "    no_decay = [\"bias\", \"LayerNorm.weight\", \"LayerNorm.bias\"]\n",
    "    optimizer_grouped_parameters = []\n",
    "    processed_params = set()\n",
    "    \n",
    "    # 1. Embeddings - 15% of base LR (slightly higher for polarization)\n",
    "    embeddings_params_decay = []\n",
    "    embeddings_params_no_decay = []\n",
    "    \n",
    "    for n, p in model.roberta.embeddings.named_parameters():\n",
    "        if p.requires_grad:\n",
    "            processed_params.add(id(p))\n",
    "            if any(nd in n for nd in no_decay):\n",
    "                embeddings_params_no_decay.append(p)\n",
    "            else:\n",
    "                embeddings_params_decay.append(p)\n",
    "    \n",
    "    if embeddings_params_decay:\n",
    "        optimizer_grouped_parameters.append({\n",
    "            \"params\": embeddings_params_decay,\n",
    "            \"weight_decay\": weight_decay,\n",
    "            \"lr\": learning_rate * 0.15  # ← Increased from 0.1 for better word understanding\n",
    "        })\n",
    "    if embeddings_params_no_decay:\n",
    "        optimizer_grouped_parameters.append({\n",
    "            \"params\": embeddings_params_no_decay,\n",
    "            \"weight_decay\": 0.0,\n",
    "            \"lr\": learning_rate * 0.15\n",
    "        })\n",
    "    \n",
    "    # 2. Encoder layers - gradually increasing LR\n",
    "    num_layers = model.roberta.config.num_hidden_layers\n",
    "    \n",
    "    for layer_num in range(num_layers):\n",
    "        layer = model.roberta.encoder.layer[layer_num]\n",
    "        # Smoother gradient: 15% to 100%\n",
    "        layer_lr_multiplier = 0.15 + (0.85 * layer_num / (num_layers - 1))\n",
    "        \n",
    "        layer_params_decay = []\n",
    "        layer_params_no_decay = []\n",
    "        \n",
    "        for n, p in layer.named_parameters():\n",
    "            if p.requires_grad and id(p) not in processed_params:\n",
    "                processed_params.add(id(p))\n",
    "                if any(nd in n for nd in no_decay):\n",
    "                    layer_params_no_decay.append(p)\n",
    "                else:\n",
    "                    layer_params_decay.append(p)\n",
    "        \n",
    "        if layer_params_decay:\n",
    "            optimizer_grouped_parameters.append({\n",
    "                \"params\": layer_params_decay,\n",
    "                \"weight_decay\": weight_decay,\n",
    "                \"lr\": learning_rate * layer_lr_multiplier\n",
    "            })\n",
    "        if layer_params_no_decay:\n",
    "            optimizer_grouped_parameters.append({\n",
    "                \"params\": layer_params_no_decay,\n",
    "                \"weight_decay\": 0.0,\n",
    "                \"lr\": learning_rate * layer_lr_multiplier\n",
    "            })\n",
    "    \n",
    "    # 3. Task-specific layers (attention, classifier) - 2x base LR\n",
    "    task_params_decay = []\n",
    "    task_params_no_decay = []\n",
    "    \n",
    "    for n, p in model.named_parameters():\n",
    "        if p.requires_grad and id(p) not in processed_params:\n",
    "            if \"classifier\" in n or \"attention\" in n:\n",
    "                processed_params.add(id(p))\n",
    "                if any(nd in n for nd in no_decay):\n",
    "                    task_params_no_decay.append(p)\n",
    "                else:\n",
    "                    task_params_decay.append(p)\n",
    "    \n",
    "    if task_params_decay:\n",
    "        optimizer_grouped_parameters.append({\n",
    "            \"params\": task_params_decay,\n",
    "            \"weight_decay\": weight_decay,\n",
    "            \"lr\": learning_rate * 2.0  # Fast adaptation to polarization patterns\n",
    "        })\n",
    "    if task_params_no_decay:\n",
    "        optimizer_grouped_parameters.append({\n",
    "            \"params\": task_params_no_decay,\n",
    "            \"weight_decay\": 0.0,\n",
    "            \"lr\": learning_rate * 2.0\n",
    "        })\n",
    "    \n",
    "    return optimizer_grouped_parameters\n",
    "\n",
    "# ============================================\n",
    "# OPTIMIZER WITH LAYERWISE LR\n",
    "# ============================================\n",
    "BASE_LR = CONFIG['learning_rate']  # 3e-5\n",
    "optimizer_params = get_optimizer_grouped_parameters(\n",
    "    model, \n",
    "    BASE_LR, \n",
    "    weight_decay=CONFIG['weight_decay']\n",
    ")\n",
    "\n",
    "optimizer = AdamW(\n",
    "    optimizer_params,\n",
    "    betas=(0.9, 0.999),\n",
    "    eps=1e-8\n",
    ")\n",
    "\n",
    "print(f\"\\n✓ Layerwise Learning Rates (Optimized for Polarization):\")\n",
    "print(f\"  Embeddings:      {BASE_LR * 0.15:.2e} (15% - word meaning)\")\n",
    "print(f\"  Lower layers:    {BASE_LR * 0.15:.2e} - {BASE_LR * 0.5:.2e} (context)\")\n",
    "print(f\"  Upper layers:    {BASE_LR * 0.5:.2e} - {BASE_LR:.2e} (semantics)\")\n",
    "print(f\"  Classifier:      {BASE_LR * 2.0:.2e} (200% - task-specific)\")\n",
    "\n",
    "# ============================================\n",
    "# ONE-CYCLE LR SCHEDULER\n",
    "# ============================================\n",
    "total_steps = len(train_loader) * CONFIG['num_epochs'] // CONFIG['gradient_accumulation_steps']\n",
    "\n",
    "scheduler = OneCycleLR(\n",
    "    optimizer,\n",
    "    max_lr=[param_group['lr'] for param_group in optimizer.param_groups],\n",
    "    total_steps=total_steps,\n",
    "    pct_start=0.1,  # 10% warmup\n",
    "    anneal_strategy='cos',\n",
    "    div_factor=25.0,\n",
    "    final_div_factor=10000.0\n",
    ")\n",
    "\n",
    "print(f\"\\n✓ OneCycleLR Scheduler:\")\n",
    "print(f\"  Total steps: {total_steps}\")\n",
    "print(f\"  Warmup steps: {int(total_steps * 0.1)} (10%)\")\n",
    "print(f\"  Annealing: Cosine\")\n",
    "\n",
    "# Training history\n",
    "history = {\n",
    "    'train_loss': [],\n",
    "    'train_macro_f1': [],\n",
    "    'val_loss': [],\n",
    "    'val_macro_f1': [],\n",
    "    'val_weighted_f1': []\n",
    "}\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"POLARIZATION DETECTION TRAINING \")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\n  Training Configuration:\")\n",
    "print(f\"  Epochs: {CONFIG['num_epochs']}\")\n",
    "print(f\"  Batch size: {CONFIG['batch_size']} (effective: {CONFIG['batch_size'] * CONFIG['gradient_accumulation_steps']})\")\n",
    "print(f\"  Base LR: {BASE_LR:.2e}\")\n",
    "print(f\"  Warmup: 10% of training\")\n",
    "print(f\"  Device: {device}\")\n",
    "print(f\"\\n⏱️  Estimated Time: ~45-60 minutes\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\n\")\n",
    "\n",
    "best_val_macro_f1 = 0\n",
    "best_epoch = 0\n",
    "patience = 0\n",
    "early_stopping_patience = 3\n",
    "\n",
    "for epoch in range(CONFIG['num_epochs']):\n",
    "    print(f\"\\nEpoch {epoch + 1}/{CONFIG['num_epochs']}\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    try:\n",
    "        # Train\n",
    "        train_loss, train_macro_f1 = train_epoch(\n",
    "            model, train_loader, optimizer, scheduler, device\n",
    "        )\n",
    "        \n",
    "        print(f\"Train Loss: {train_loss:.4f} | Train Macro-F1: {train_macro_f1:.4f}\")\n",
    "\n",
    "        # Validate (no TTA during training for speed)\n",
    "        val_results = evaluate(model, val_loader, device, threshold=0.5, use_tta=False)\n",
    "        print(f\"Val Loss: {val_results['loss']:.4f} | Val Macro-F1: {val_results['macro_f1']:.4f} | Val Weighted-F1: {val_results['weighted_f1']:.4f}\")\n",
    "        \n",
    "        # Calculate train-val gap (overfitting indicator)\n",
    "        f1_gap = train_macro_f1 - val_results['macro_f1']\n",
    "        gap_status = \" OVERFITTING\" if f1_gap > 0.10 else \"✓\"\n",
    "        print(f\"Train-Val Gap: {f1_gap:+.4f} {gap_status}\")\n",
    "\n",
    "        # Save history\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['train_macro_f1'].append(train_macro_f1)\n",
    "        history['val_loss'].append(val_results['loss'])\n",
    "        history['val_macro_f1'].append(val_results['macro_f1'])\n",
    "        history['val_weighted_f1'].append(val_results['weighted_f1'])\n",
    "\n",
    "        # Save best model (based on Macro F1)\n",
    "        if val_results['macro_f1'] > best_val_macro_f1:\n",
    "            best_val_macro_f1 = val_results['macro_f1']\n",
    "            best_epoch = epoch + 1\n",
    "            patience = 0\n",
    "            \n",
    "            # Save checkpoint\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'scheduler_state_dict': scheduler.state_dict(),\n",
    "                'val_macro_f1': val_results['macro_f1'],\n",
    "                'val_weighted_f1': val_results['weighted_f1'],\n",
    "                'config': CONFIG,\n",
    "                'history': history,\n",
    "                'model_name': MODEL_NAME  \n",
    "            \n",
    "            print(f\" SAVED BEST MODEL! (Val Macro-F1: {best_val_macro_f1:.4f})\")\n",
    "            \n",
    "        else:\n",
    "            patience += 1\n",
    "            print(f\"No improvement for {patience} epoch(s). Best: {best_val_macro_f1:.4f}\")\n",
    "            \n",
    "            if patience >= early_stopping_patience:\n",
    "                print(f\"\\n EARLY STOPPING TRIGGERED!\")\n",
    "                print(f\"   No improvement for {early_stopping_patience} consecutive epochs.\")\n",
    "                print(f\"   Best Val Macro F1: {best_val_macro_f1:.4f} at epoch {best_epoch}\")\n",
    "                break\n",
    "\n",
    "        # Memory monitoring (first epoch only)\n",
    "        if torch.cuda.is_available() and epoch == 0:\n",
    "            allocated = torch.cuda.memory_allocated(0) / 1024**3\n",
    "            reserved = torch.cuda.memory_reserved(0) / 1024**3\n",
    "            print(f\"GPU Memory: {allocated:.2f} GB allocated, {reserved:.2f} GB reserved\")\n",
    "            \n",
    "    except RuntimeError as e:\n",
    "        print(f\"\\n Runtime Error: {e}\")\n",
    "        \n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(f\" TRAINING COMPLETE!\")\n",
    "print(f\" Best Model: Epoch {best_epoch}\")\n",
    "print(f\" Best Val Macro F1: {best_val_macro_f1:.4f}\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Loss plot\n",
    "axes[0].plot(history['train_loss'], label='Train Loss', marker='o', linewidth=2.5, color='#3498db')\n",
    "axes[0].plot(history['val_loss'], label='Val Loss', marker='s', linewidth=2.5, color='#e74c3c')\n",
    "axes[0].axvline(x=best_epoch-1, color='green', linestyle='--', alpha=0.7, linewidth=2, label=f'Best Epoch ({best_epoch})')\n",
    "axes[0].set_xlabel('Epoch', fontsize=13, fontweight='bold')\n",
    "axes[0].set_ylabel('Loss', fontsize=13, fontweight='bold')\n",
    "axes[0].set_title('Training and Validation Loss', fontsize=15, fontweight='bold')\n",
    "axes[0].legend(fontsize=11)\n",
    "axes[0].grid(True, alpha=0.3, linestyle='--')\n",
    "\n",
    "# F1 plot with targets\n",
    "axes[1].plot(history['train_macro_f1'], label='Train Macro F1', marker='o', linewidth=2.5, color='#3498db')\n",
    "axes[1].plot(history['val_macro_f1'], label='Val Macro F1', marker='s', linewidth=2.5, color='#e74c3c')\n",
    "axes[1].axhline(y=best_val_macro_f1, color='green', linestyle='--', alpha=0.7, linewidth=2, label=f'Best: {best_val_macro_f1:.4f}')\n",
    "axes[1].axhline(y=0.82, color='gold', linestyle=':', alpha=0.7, linewidth=2.5, label='Target: 82%')\n",
    "axes[1].axhline(y=0.80, color='orange', linestyle=':', alpha=0.5, linewidth=2, label='Minimum: 80%')\n",
    "axes[1].axvline(x=best_epoch-1, color='green', linestyle='--', alpha=0.7, linewidth=2)\n",
    "axes[1].set_xlabel('Epoch', fontsize=13, fontweight='bold')\n",
    "axes[1].set_ylabel('Macro F1 Score', fontsize=13, fontweight='bold')\n",
    "axes[1].set_title('Macro F1 Score Progress', fontsize=15, fontweight='bold')\n",
    "axes[1].legend(fontsize=10, loc='lower right')\n",
    "axes[1].grid(True, alpha=0.3, linestyle='--')\n",
    "axes[1].set_ylim([0.65, 0.90])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n Training Summary:\")\n",
    "print(f\"  Best epoch: {best_epoch}/{CONFIG['num_epochs']}\")\n",
    "print(f\"  Best Val Macro F1: {best_val_macro_f1:.4f}\")\n",
    "if len(history['train_macro_f1']) > 0:\n",
    "    print(f\"  Final Train F1: {history['train_macro_f1'][-1]:.4f}\")\n",
    "    print(f\"  Final Val F1: {history['val_macro_f1'][-1]:.4f}\")\n",
    "    final_gap = history['train_macro_f1'][-1] - history['val_macro_f1'][-1]\n",
    "    print(f\"  Final Train-Val Gap: {final_gap:+.4f} {'(Good generalization ✓)' if abs(final_gap) < 0.08 else '(Check for overfitting )'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9qq8GZNZAAZk",
    "outputId": "538b3e61-de67-43b1-ce28-deee5f98f994",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ====================\n",
    "# CELL 11: Final Evaluation with TTA\n",
    "# ====================\n",
    "import torch\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FINAL MODEL EVALUATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Load best model\n",
    "checkpoint = torch.load('/kaggle/input/best-model-4-large-careful/transformers/default/1/best_model_4_large_careful.pt', weights_only=False)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "print(f\"✓ Loaded best model from epoch {checkpoint['epoch'] + 1}\")\n",
    "print(f\"  Best validation Macro F1: {checkpoint['val_macro_f1']:.4f}\")\n",
    "print(f\"  Best validation Weighted F1: {checkpoint['val_weighted_f1']:.4f}\\n\")\n",
    "\n",
    "# Step 1: Optimize threshold on validation set\n",
    "print(\"Step 1: Finding optimal threshold...\")\n",
    "best_threshold = optimize_threshold(model, val_loader, device)\n",
    "\n",
    "# Step 2: Evaluate on test set with TTA\n",
    "print(f\"\\nStep 2: Evaluating on test set with TTA (n={CONFIG['tta_iterations']})...\")\n",
    "test_results = evaluate(\n",
    "    model,\n",
    "    test_loader,\n",
    "    device,\n",
    "    threshold=best_threshold,\n",
    "    use_tta=True\n",
    ")\n",
    "\n",
    "# Calculate additional metrics\n",
    "test_preds = test_results['predictions']\n",
    "test_labels = test_results['labels']\n",
    "\n",
    "weighted_f1 = f1_score(test_labels, test_preds, average='weighted')\n",
    "precision, recall, f1, support = precision_recall_fscore_support(\n",
    "    test_labels, test_preds, average=None\n",
    ")\n",
    "\n",
    "# Display results\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FINAL TEST RESULTS\")\n",
    "print(\"=\"*70)\n",
    "print(f\" PRIMARY METRICS:\")\n",
    "print(f\"  {'Macro F1-Score:':<30} {test_results['macro_f1']:.4f} {'✅ TARGET MET!' if test_results['macro_f1'] >= 0.80 else '⭐ (Target: 80%+)'}\")\n",
    "print(f\"  {'Weighted F1-Score:':<30} {weighted_f1:.4f}\")\n",
    "print(f\"  {'Optimal Threshold:':<30} {best_threshold:.3f}\")\n",
    "print(f\"  {'TTA Iterations:':<30} {CONFIG['tta_iterations']}\")\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"PER-CLASS PERFORMANCE:\")\n",
    "print(\"=\"*70)\n",
    "class_names = ['Non-Hate (Class 0)', 'Hate Speech (Class 1)']\n",
    "for i, (name, prec, rec, f1_class, sup) in enumerate(zip(class_names, precision, recall, f1, support)):\n",
    "    print(f\"{name}:\")\n",
    "    print(f\"  F1-Score:  {f1_class:.4f}\")\n",
    "    print(f\"  Precision: {prec:.4f}\")\n",
    "    print(f\"  Recall:    {rec:.4f}\")\n",
    "    print(f\"  Support:   {int(sup)}\")\n",
    "    print()\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"DETAILED CLASSIFICATION REPORT:\")\n",
    "print(\"=\"*70)\n",
    "print(classification_report(test_labels, test_preds, target_names=['Non-Hate', 'Hate Speech']))\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"CONFUSION MATRIX:\")\n",
    "print(\"=\"*70)\n",
    "cm = confusion_matrix(test_labels, test_preds)\n",
    "print(cm)\n",
    "print(f\"\\n  True Negatives:  {cm[0,0]}\")\n",
    "print(f\"  False Positives: {cm[0,1]}\")\n",
    "print(f\"  False Negatives: {cm[1,0]}\")\n",
    "print(f\"  True Positives:  {cm[1,1]}\")\n",
    "overall_acc = accuracy_score(test_labels, test_preds)\n",
    "print(f\"\\nOverall Test Accuracy: {overall_acc:.4f}\")\n",
    "\n",
    "# Per-Language Performance\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PER-LANGUAGE MACRO F1 SCORES:\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "test_preds_array = np.array(test_preds)\n",
    "test_labels_array = np.array(test_labels)\n",
    "test_df_reset = test_df.reset_index(drop=True)\n",
    "\n",
    "lang_results = {}\n",
    "for lang, lang_name in [('en', 'English'), ('es', 'Spanish'), ('de', 'German')]:\n",
    "    lang_mask = test_df_reset['language'] == lang\n",
    "    lang_indices = lang_mask[lang_mask].index.tolist()\n",
    "\n",
    "    if len(lang_indices) > 0:\n",
    "        lang_preds = test_preds_array[lang_indices]\n",
    "        lang_labels = test_labels_array[lang_indices]\n",
    "\n",
    "        lang_macro_f1 = f1_score(lang_labels, lang_preds, average='macro')\n",
    "        lang_weighted_f1 = f1_score(lang_labels, lang_preds, average='weighted')\n",
    "        lang_acc = accuracy_score(lang_labels, lang_preds)\n",
    "\n",
    "        lang_results[lang_name] = {\n",
    "            'macro_f1': lang_macro_f1,\n",
    "            'weighted_f1': lang_weighted_f1,\n",
    "            'accuracy': lang_acc\n",
    "        }\n",
    "\n",
    "        print(f\"{lang_name}:\")\n",
    "        print(f\"  Macro F1:    {lang_macro_f1:.4f}\")\n",
    "        print(f\"  Weighted F1: {lang_weighted_f1:.4f}\")\n",
    "        print(f\"  Accuracy:    {lang_acc:.4f}\")\n",
    "        print(f\"  Samples:     {len(lang_preds)}\")\n",
    "        print()\n",
    "\n",
    "# Summary\n",
    "print(\"=\"*70)\n",
    "if test_results['macro_f1'] >= 0.80:\n",
    "    print(f\" SUCCESS! MACRO F1-SCORE: {test_results['macro_f1']:.4f}\")\n",
    "    print(f\" Target of 80%+ ACHIEVED!\")\n",
    "else:\n",
    "    print(f\" FINAL MACRO F1-SCORE: {test_results['macro_f1']:.4f}\")\n",
    "    improvement_needed = 0.80 - test_results['macro_f1']\n",
    "    print(f\"  {improvement_needed:.2%} away from 80% target\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Visualize confusion matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Non-Hate', 'Hate Speech'],\n",
    "            yticklabels=['Non-Hate', 'Hate Speech'],\n",
    "            cbar_kws={'label': 'Count'})\n",
    "plt.title(f'Confusion Matrix\\nMacro F1: {test_results[\"macro_f1\"]:.4f} | TTA: {CONFIG[\"tta_iterations\"]}', \n",
    "          fontsize=14, fontweight='bold')\n",
    "plt.ylabel('True Label', fontsize=12)\n",
    "plt.xlabel('Predicted Label', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Detailed breakdown\n",
    "print(f\"\\n📊 PERFORMANCE BREAKDOWN:\")\n",
    "print(f\"  Training Optimization:\")\n",
    "print(f\"    - Layerwise Learning Rates: \")\n",
    "print(f\"    - OneCycleLR Scheduler \")\n",
    "print(f\"    - Data Augmentation\")\n",
    "print(f\"    - Class-Balanced Focal Loss\")\n",
    "print(f\"    - Multi-Sample Dropout\")\n",
    "print(f\"  Evaluation:\")\n",
    "print(f\"    - Test-Time Augmentation: {CONFIG['tta_iterations']}x\")\n",
    "print(f\"    - Threshold Optimization: {best_threshold:.3f}\")\n",
    "print(f\"\\n  Results by Language:\")\n",
    "for lang_name, results in lang_results.items():\n",
    "    print(f\"    {lang_name}: {results['macro_f1']:.4f}\")\n",
    "\n",
    "print(f\"\\n Best model saved as: best_xlm_roberta_macro_f1.pt\")\n",
    "print(f\" Final Test Macro F1: {test_results['macro_f1']:.4f}\")\n",
    "print(f\" Validation-Test Gap: {checkpoint['val_macro_f1'] - test_results['macro_f1']:.4f}\")\n",
    "\n",
    "# Store final results\n",
    "final_results = {\n",
    "    'test_macro_f1': test_results['macro_f1'],\n",
    "    'test_weighted_f1': weighted_f1,\n",
    "    'test_accuracy': overall_acc,\n",
    "    'val_macro_f1': checkpoint['val_macro_f1'],\n",
    "    'optimal_threshold': best_threshold,\n",
    "    'tta_iterations': CONFIG['tta_iterations'],\n",
    "    'best_epoch': checkpoint['epoch'] + 1,\n",
    "    'per_language': lang_results\n",
    "}\n",
    "\n",
    "print(f\"\\n Evaluation complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NZ3wFtANAAZl",
    "outputId": "19424187-8934-4496-b7d2-b493a6ca49da",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ====================\n",
    "# CELL 12: Visualizations\n",
    "# ====================\n",
    "# ====================\n",
    "# Load saved training history (if running after restart)\n",
    "# ====================\n",
    "import json\n",
    "\n",
    "if 'history' not in globals():\n",
    "    try:\n",
    "        with open('/kaggle/input/outputjson/xlm_roberta_macro_f1_optimized_results.json', 'r') as f:\n",
    "            saved = json.load(f)\n",
    "            history = saved['training_history']\n",
    "        print(\" Loaded training history from JSON\")\n",
    "    except FileNotFoundError:\n",
    "        raise ValueError(\"History is not defined and training_results.json was not found.\")\n",
    "\n",
    "# Create results directory\n",
    "os.makedirs('results', exist_ok=True)\n",
    "os.makedirs('plots', exist_ok=True)\n",
    "\n",
    "# Plot 1: Training History\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Loss plot\n",
    "axes[0].plot(history['train_loss'], label='Train Loss', marker='o', linewidth=2)\n",
    "axes[0].plot(history['val_loss'], label='Val Loss', marker='s', linewidth=2)\n",
    "axes[0].set_xlabel('Epoch', fontsize=12)\n",
    "axes[0].set_ylabel('Loss', fontsize=12)\n",
    "axes[0].set_title('Training and Validation Loss', fontsize=14, fontweight='bold')\n",
    "axes[0].legend(fontsize=11)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# F1 plot instead of accuracy\n",
    "axes[1].plot(history['train_macro_f1'], label='Train Macro F1', marker='o', linewidth=2)\n",
    "axes[1].plot(history['val_macro_f1'], label='Val Macro F1', marker='s', linewidth=2)\n",
    "axes[1].set_xlabel('Epoch', fontsize=12)\n",
    "axes[1].set_ylabel('Macro F1-Score', fontsize=12)\n",
    "axes[1].set_title('Training and Validation Macro F1-Score', fontsize=14, fontweight='bold')\n",
    "axes[1].legend(fontsize=11)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('plots/training_history.pdf', dpi=300, bbox_inches='tight')\n",
    "plt.savefig('plots/training_history.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\" Training history plot saved!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hGXSndLsAAZm",
    "outputId": "52f54376-12d8-41fa-ef6c-122075c9ef27",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ====================\n",
    "# CELL 13: Save Results & Final Summary (FIXED)\n",
    "# ====================\n",
    "# ====================\n",
    "# LOAD BEST EPOCH & BEST VAL F1 IF NOT DEFINED\n",
    "# ====================\n",
    "import json\n",
    "\n",
    "if 'best_epoch' not in globals() or 'best_val_macro_f1' not in globals():\n",
    "    print(\"best_epoch / best_val_macro_f1 not found in memory — loading from results JSON...\")\n",
    "\n",
    "    # Try loading from your results file\n",
    "    try:\n",
    "        with open('/kaggle/input/outputjson/xlm_roberta_macro_f1_optimized_results.json', 'r') as f:\n",
    "            saved = json.load(f)\n",
    "\n",
    "        best_epoch = saved['training_history']['best_epoch']\n",
    "        best_val_macro_f1 = saved['training_history']['best_val_macro_f1']\n",
    "\n",
    "        print(f\" Loaded best_epoch={best_epoch}, best_val_macro_f1={best_val_macro_f1:.4f}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        raise ValueError(\n",
    "            \" ERROR: best_epoch is not defined and cannot be found in saved results.\\n\"\n",
    "            \"Make sure to run the training cell first!\"\n",
    "        ) from e\n",
    "\n",
    "if 'history' not in globals():\n",
    "    try:\n",
    "        with open('/kaggle/working/results/xlm_roberta_macro_f1_optimized_results.json', 'r') as f:\n",
    "            saved = json.load(f)\n",
    "            history = saved['training_history']\n",
    "        print(\" Loaded training history from JSON\")\n",
    "    except FileNotFoundError:\n",
    "        raise ValueError(\"History is not defined and training_results.json was not found.\")\n",
    "# Extract test results from Cell 11\n",
    "test_acc = accuracy_score(test_labels, test_preds)\n",
    "macro_f1 = test_results['macro_f1']  # ← FIX: Get from test_results dict\n",
    "weighted_f1 = test_results['weighted_f1']  # ← FIX: Get from test_results dict\n",
    "\n",
    "# Save complete results to JSON\n",
    "results = {\n",
    "    'model': 'XLM-RoBERTa-Large-MacroF1-Optimized',\n",
    "    'task': 'Binary Polarization Detection',\n",
    "    'configuration': CONFIG,\n",
    "    'data_info': {\n",
    "        'train_samples': len(train_df),\n",
    "        'val_samples': len(val_df),\n",
    "        'test_samples': len(test_df),\n",
    "        'num_classes': num_classes,\n",
    "        'languages': ['English', 'Spanish', 'German'],\n",
    "        'augmented_samples': 584,\n",
    "        'final_balance': '1.016:1 (50.4% vs 49.6%)'\n",
    "    },\n",
    "    'training_history': {\n",
    "        'train_loss': [float(x) for x in history['train_loss']],\n",
    "        'train_macro_f1': [float(x) for x in history['train_macro_f1']],\n",
    "        'val_loss': [float(x) for x in history['val_loss']],\n",
    "        'val_macro_f1': [float(x) for x in history['val_macro_f1']],\n",
    "        'val_weighted_f1': [float(x) for x in history['val_weighted_f1']],\n",
    "        'best_epoch': int(best_epoch),\n",
    "        'best_val_macro_f1': float(best_val_macro_f1)\n",
    "    },\n",
    "    'test_results': {\n",
    "        'accuracy': float(test_acc),\n",
    "        'macro_f1': float(macro_f1),\n",
    "        'weighted_f1': float(weighted_f1),\n",
    "        'optimal_threshold': float(best_threshold),\n",
    "        'precision': float(precision_recall_fscore_support(test_labels, test_preds, average='weighted')[0]),\n",
    "        'recall': float(precision_recall_fscore_support(test_labels, test_preds, average='weighted')[1]),\n",
    "        'tta_iterations': CONFIG['tta_iterations']\n",
    "    },\n",
    "    'per_language_results': lang_results,  \n",
    "    'per_class_f1': {\n",
    "        'non_polarized': float(test_results['per_class_f1'][0]),\n",
    "        'polarized': float(test_results['per_class_f1'][1])\n",
    "    }\n",
    "}\n",
    "\n",
    "# Create results directory if it doesn't exist\n",
    "import os\n",
    "os.makedirs('results', exist_ok=True)\n",
    "os.makedirs('plots', exist_ok=True)\n",
    "\n",
    "# Save to JSON\n",
    "with open('results/xlm_roberta_macro_f1_optimized_results.json', 'w') as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "\n",
    "print(\" Results saved to: results/xlm_roberta_macro_f1_optimized_results.json\")\n",
    "\n",
    "# Final Summary\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FINAL SUMMARY - XLM-RoBERTa MACRO F1 OPTIMIZED\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Task: Binary Polarization Detection\")\n",
    "print(f\"  Class 0: Non-polarized speech\")\n",
    "print(f\"  Class 1: Polarized speech\")\n",
    "\n",
    "print(f\"\\nModel: XLM-RoBERTa with Macro F1 Optimizations\")\n",
    "print(f\"  ✓ Class-balanced focal loss (α={CONFIG['focal_alpha']}, γ={CONFIG['focal_gamma']})\")\n",
    "print(f\"  ✓ Multi-sample dropout (n={CONFIG['num_dropouts']})\")\n",
    "print(f\"  ✓ Attention pooling\")\n",
    "print(f\"  ✓ Mixup augmentation (α={CONFIG['mixup_alpha']})\")\n",
    "print(f\"  ✓ Test-time augmentation (n={CONFIG['tta_iterations']})\")\n",
    "print(f\"  ✓ Threshold optimization\")\n",
    "\n",
    "print(f\"\\nData:\")\n",
    "print(f\"  Languages: English, Spanish, German\")\n",
    "print(f\"  Training samples: {len(train_df):,} (including {results['data_info']['augmented_samples']} augmented)\")\n",
    "print(f\"  Validation samples: {len(val_df):,}\")\n",
    "print(f\"  Test samples: {len(test_df):,}\")\n",
    "print(f\"  Balance: {results['data_info']['final_balance']}\")\n",
    "\n",
    "print(f\"\\nTraining:\")\n",
    "print(f\"  Best Epoch: {best_epoch}\")\n",
    "print(f\"  Best Val Macro F1: {best_val_macro_f1:.4f}\")\n",
    "print(f\"  Training time: ~25 minutes\")\n",
    "print(f\"  Early stopping: Triggered at epoch 9 (patience=3)\")\n",
    "\n",
    "print(f\"\\n\" + \"=\"*70)\n",
    "print(f\"TEST PERFORMANCE (PRIMARY RESULTS)\")\n",
    "print(f\"=\"*70)\n",
    "print(f\"   Macro F1:    {macro_f1:.4f} (Target: 80%)\")\n",
    "print(f\"   Weighted F1: {weighted_f1:.4f}\")\n",
    "print(f\"   Accuracy:    {test_acc:.4f}\")\n",
    "print(f\"    Threshold:   {best_threshold:.3f}\")\n",
    "\n",
    "print(f\"\\nPer-Class Performance:\")\n",
    "print(f\"  Non-Polarized (Class 0): F1 = {test_results['per_class_f1'][0]:.4f}\")\n",
    "print(f\"  Polarized (Class 1):     F1 = {test_results['per_class_f1'][1]:.4f}\")\n",
    "\n",
    "print(f\"\\nPer-Language Macro F1:\")\n",
    "for lang, metrics in lang_results.items():\n",
    "    print(f\"  {lang:8s}: {metrics['macro_f1']:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "\n",
    "print(f\"  Current Test F1: {macro_f1:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FILES SAVED\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\" EVALUATION COMPLETE!\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\n Creating summary visualizations...\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a summary figure\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# Plot 1: Per-Language F1\n",
    "ax1 = axes[0, 0]\n",
    "languages = list(lang_results.keys())\n",
    "f1_scores = [m['macro_f1'] for m in lang_results.values()]\n",
    "\n",
    "colors = ['#3498db' if f1 < 0.75 else '#2ecc71' if f1 < 0.80 else '#27ae60' for f1 in f1_scores]\n",
    "\n",
    "bars = ax1.bar(languages, f1_scores, color=colors, alpha=0.7, edgecolor='black')\n",
    "ax1.axhline(y=0.80, color='red', linestyle='--', linewidth=2, label='Target (80%)', alpha=0.7)\n",
    "ax1.axhline(y=macro_f1, color='orange', linestyle=':', linewidth=2, label=f'Overall ({macro_f1:.2%})', alpha=0.7)\n",
    "ax1.set_ylabel('Macro F1 Score', fontsize=12, fontweight='bold')\n",
    "ax1.set_title('Per-Language Performance', fontsize=14, fontweight='bold')\n",
    "ax1.legend(fontsize=10)\n",
    "ax1.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add value labels on bars\n",
    "for i, (lang, f1) in enumerate(zip(languages, f1_scores)):\n",
    "    ax1.text(i, f1 + 0.01, f'{f1:.3f}', ha='center', va='bottom', fontsize=11, fontweight='bold')\n",
    "\n",
    "# Plot 2: Confusion Matrix\n",
    "ax2 = axes[0, 1]\n",
    "cm = confusion_matrix(test_labels, test_preds)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax2, cbar_kws={'label': 'Count'})\n",
    "ax2.set_xlabel('Predicted', fontsize=12, fontweight='bold')\n",
    "ax2.set_ylabel('Actual', fontsize=12, fontweight='bold')\n",
    "ax2.set_title('Confusion Matrix', fontsize=14, fontweight='bold')\n",
    "ax2.set_xticklabels(['Non-Polarized', 'Polarized'])\n",
    "ax2.set_yticklabels(['Non-Polarized', 'Polarized'])\n",
    "\n",
    "# Plot 3: Training History\n",
    "ax3 = axes[1, 0]\n",
    "epochs = range(1, len(history['val_macro_f1']) + 1)\n",
    "ax3.plot(epochs, history['train_macro_f1'], 'o-', label='Train F1', linewidth=2, markersize=6)\n",
    "ax3.plot(epochs, history['val_macro_f1'], 's-', label='Val F1', linewidth=2, markersize=6)\n",
    "ax3.axvline(x=best_epoch, color='green', linestyle='--', linewidth=2, alpha=0.5, label=f'Best Epoch ({best_epoch})')\n",
    "ax3.axhline(y=0.80, color='red', linestyle=':', linewidth=2, alpha=0.5, label='Target (80%)')\n",
    "ax3.set_xlabel('Epoch', fontsize=12, fontweight='bold')\n",
    "ax3.set_ylabel('Macro F1 Score', fontsize=12, fontweight='bold')\n",
    "ax3.set_title('Training Progress', fontsize=14, fontweight='bold')\n",
    "ax3.legend(fontsize=10)\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 4: Performance Metrics Summary\n",
    "ax4 = axes[1, 1]\n",
    "metrics = ['Macro F1', 'Weighted F1', 'Accuracy']\n",
    "scores = [macro_f1, weighted_f1, test_acc]\n",
    "colors_metrics = ['#e74c3c' if s < 0.75 else '#f39c12' if s < 0.80 else '#2ecc71' for s in scores]\n",
    "\n",
    "bars = ax4.barh(metrics, scores, color=colors_metrics, alpha=0.7, edgecolor='black')\n",
    "ax4.axvline(x=0.80, color='red', linestyle='--', linewidth=2, label='Target', alpha=0.7)\n",
    "ax4.set_xlabel('Score', fontsize=12, fontweight='bold')\n",
    "ax4.set_title('Overall Test Metrics', fontsize=14, fontweight='bold')\n",
    "ax4.set_xlim(0, 1)\n",
    "ax4.legend(fontsize=10)\n",
    "ax4.grid(axis='x', alpha=0.3)\n",
    "\n",
    "# Add value labels\n",
    "for i, (metric, score) in enumerate(zip(metrics, scores)):\n",
    "    ax4.text(score + 0.01, i, f'{score:.3f}', va='center', fontsize=11, fontweight='bold')\n",
    "\n",
    "plt.suptitle(f'XLM-RoBERTa Polarization Detection - Final Results\\nTest Macro F1: {macro_f1:.4f}', \n",
    "             fontsize=16, fontweight='bold', y=0.995)\n",
    "plt.tight_layout()\n",
    "plt.savefig('plots/final_summary.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\" Summary visualization saved to: plots/final_summary.png\")\n",
    "print(\"\\n All done! Check the results folder for detailed outputs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T13:51:19.938709Z",
     "iopub.status.busy": "2025-11-17T13:51:19.937902Z",
     "iopub.status.idle": "2025-11-17T13:52:23.677246Z",
     "shell.execute_reply": "2025-11-17T13:52:23.676339Z",
     "shell.execute_reply.started": "2025-11-17T13:51:19.938673Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "PREDICTING ON UNLABELED DEV SET\n",
      "======================================================================\n",
      "\n",
      "Loading dev set files...\n",
      "✓ Dev data loaded!\n",
      "  English:  133\n",
      "  Spanish:  165\n",
      "  German:   159\n",
      "  Total:    457\n",
      "\n",
      "Cleaning dev data...\n",
      "  457 → 457 samples\n",
      "\n",
      "======================================================================\n",
      "Loading best model...\n",
      "✓ Model loaded! Val Macro F1: 0.7585\n",
      "✓ Tokenizer loaded!\n",
      "\n",
      "⚠ Using default threshold: 0.500\n",
      "\n",
      "Generating predictions...\n",
      "  TTA: True (5 iterations)\n",
      "  Threshold: 0.500\n",
      "  Batch size: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 58/58 [00:52<00:00,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "PREDICTION STATISTICS\n",
      "======================================================================\n",
      "Total: 457\n",
      "  Class 0 (Non-polarized): 208 (45.5%)\n",
      "  Class 1 (Polarized):     249 (54.5%)\n",
      "\n",
      "Per-language:\n",
      "  English: 133 total, 66 polarized (49.6%)\n",
      "  Spanish: 165 total, 88 polarized (53.3%)\n",
      "  German: 159 total, 95 polarized (59.7%)\n",
      "\n",
      "======================================================================\n",
      "SAVING PREDICTIONS\n",
      "======================================================================\n",
      "✓ Saved: /kaggle/working/dev_predictions_all.csv\n",
      " Saved: /kaggle/working/en_dev_predictions.csv\n",
      " Saved: /kaggle/working/es_dev_predictions.csv\n",
      " Saved: /kaggle/working/de_dev_predictions.csv\n",
      "\n",
      "======================================================================\n",
      "COMPLETE!\n",
      "======================================================================\n",
      "\n",
      "Output files:\n",
      "  1. dev_predictions_all.csv (combined)\n",
      "  2. en_dev_predictions.csv\n",
      "  3. es_dev_predictions.csv\n",
      "  4. de_dev_predictions.csv\n",
      "\n",
      "Columns: id, text, polarization (0/1), confidence, language\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ====================\n",
    "# CELL 14: Predict on Unlabeled Dev Set\n",
    "# ====================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"PREDICTING ON UNLABELED DEV SET\")\n",
    "print(\"=\"*70)\n",
    "# Fallback config (in case not saved in checkpoint)\n",
    "DEFAULT_CONFIG = {\n",
    "    'model_name': 'xlm-roberta-large',\n",
    "    'dropout': 0.2,\n",
    "    'num_dropouts': 5,\n",
    "    'focal_alpha': 0.25,\n",
    "    'focal_gamma': 2.0,\n",
    "    'batch_size': 8,\n",
    "    'tta_iterations': 5\n",
    "}\n",
    "# ============================================\n",
    "# STEP 1: Load Dev Set\n",
    "# ============================================\n",
    "def load_dev_data():\n",
    "    \"\"\"Load all three dev sets (English, Spanish, German).\"\"\"\n",
    "    print(\"\\nLoading dev set files...\")\n",
    "    \n",
    "    # Load dev data\n",
    "    eng_dev = pd.read_csv('/kaggle/input/dev-dataset/eng_dev.csv', encoding='utf-8')\n",
    "    spa_dev = pd.read_csv('/kaggle/input/dev-dataset/spa_dev.csv', encoding='utf-8')\n",
    "    deu_dev = pd.read_csv('/kaggle/input/dev-dataset/deu_dev.csv', encoding='utf-8')\n",
    "    \n",
    "    # Add language identifier\n",
    "    eng_dev['language'] = 'en'\n",
    "    spa_dev['language'] = 'es'\n",
    "    deu_dev['language'] = 'de'\n",
    "    \n",
    "    # Combine all dev data\n",
    "    dev_df = pd.concat([eng_dev, spa_dev, deu_dev], ignore_index=True)\n",
    "    \n",
    "    print(f\"✓ Dev data loaded!\")\n",
    "    print(f\"  English:  {len(eng_dev)}\")\n",
    "    print(f\"  Spanish:  {len(spa_dev)}\")\n",
    "    print(f\"  German:   {len(deu_dev)}\")\n",
    "    print(f\"  Total:    {len(dev_df)}\")\n",
    "    \n",
    "    return dev_df, eng_dev, spa_dev, deu_dev\n",
    "\n",
    "# ============================================\n",
    "# STEP 2: Clean Dev Data\n",
    "# ============================================\n",
    "def clean_dev_data(df):\n",
    "    \"\"\"Minimal cleaning - keep duplicates!\"\"\"\n",
    "    print(\"\\nCleaning dev data...\")\n",
    "    initial_size = len(df)\n",
    "    \n",
    "    df = df.dropna(subset=['text'])\n",
    "    df = df[df['text'].str.strip() != '']\n",
    "    df = df.reset_index(drop=True)\n",
    "    \n",
    "    print(f\"  {initial_size} → {len(df)} samples\")\n",
    "    return df\n",
    "\n",
    "# ============================================\n",
    "# STEP 3: Dataset for Prediction\n",
    "# ============================================\n",
    "class DevDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, texts, tokenizer, max_length=128):\n",
    "        self.texts = texts\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            max_length=self.max_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten()\n",
    "        }\n",
    "\n",
    "# ============================================\n",
    "# STEP 4: Prediction with TTA\n",
    "# ============================================\n",
    "def predict_with_tta_batch(model, batch, device, threshold=0.5, n_iterations=5):\n",
    "    model.eval()\n",
    "    all_logits = []\n",
    "    \n",
    "    input_ids = batch['input_ids'].to(device)\n",
    "    attention_mask = batch['attention_mask'].to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for _ in range(n_iterations):\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            all_logits.append(outputs['logits'])\n",
    "    \n",
    "    avg_logits = torch.stack(all_logits).mean(dim=0)\n",
    "    probs = F.softmax(avg_logits, dim=1)\n",
    "    preds = (probs[:, 1] >= threshold).long()\n",
    "    \n",
    "    return preds.cpu().numpy(), probs.cpu().numpy()\n",
    "\n",
    "# ============================================\n",
    "# STEP 5: Generate Predictions\n",
    "# ============================================\n",
    "def generate_predictions(model, dev_df, tokenizer, device, threshold=0.5, batch_size=8, use_tta=True, tta_iterations=5):\n",
    "    print(f\"\\nGenerating predictions...\")\n",
    "    print(f\"  TTA: {use_tta} ({tta_iterations} iterations)\" if use_tta else \"  TTA: False\")\n",
    "    print(f\"  Threshold: {threshold:.3f}\")\n",
    "    print(f\"  Batch size: {batch_size}\")\n",
    "    \n",
    "    dev_dataset = DevDataset(dev_df['text'].tolist(), tokenizer, max_length=128)\n",
    "    dev_loader = torch.utils.data.DataLoader(dev_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    all_preds = []\n",
    "    all_probs = []\n",
    "    model.eval()\n",
    "    \n",
    "    for batch in tqdm(dev_loader, desc='Predicting'):\n",
    "        if use_tta:\n",
    "            preds, probs = predict_with_tta_batch(model, batch, device, threshold, tta_iterations)\n",
    "        else:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "                probs = F.softmax(outputs['logits'], dim=1)\n",
    "                preds = (probs[:, 1] >= threshold).long()\n",
    "            \n",
    "            preds = preds.cpu().numpy()\n",
    "            probs = probs.cpu().numpy()\n",
    "        \n",
    "        all_preds.extend(preds)\n",
    "        all_probs.extend(probs)\n",
    "    \n",
    "    return np.array(all_preds), np.array(all_probs)\n",
    "\n",
    "# ============================================\n",
    "# MAIN EXECUTION\n",
    "# ============================================\n",
    "\n",
    "# Load dev data\n",
    "dev_df, eng_dev, spa_dev, deu_dev = load_dev_data()\n",
    "\n",
    "# Clean\n",
    "dev_df_clean = clean_dev_data(dev_df)\n",
    "\n",
    "# Load model\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Loading best model...\")\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "checkpoint = torch.load('/kaggle/input/best-model-4-large-careful/transformers/default/1/best_model_4_large_careful.pt', weights_only=False)\n",
    "\n",
    "# Get saved config\n",
    "saved_config = checkpoint.get('config', DEFAULT_CONFIG)\n",
    "\n",
    "# Initialize model\n",
    "class_weights = torch.tensor([1.0, 1.0], dtype=torch.float32).to(device)\n",
    "model = MacroF1OptimizedModel(\n",
    "    num_classes=2,\n",
    "    model_name=saved_config['model_name'],\n",
    "    dropout=saved_config['dropout'],\n",
    "    num_dropouts=saved_config['num_dropouts'],\n",
    "    class_weights=class_weights,\n",
    "    focal_alpha=saved_config['focal_alpha'],\n",
    "    focal_gamma=saved_config['focal_gamma']\n",
    ")\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "print(f\"✓ Model loaded! Val Macro F1: {checkpoint['val_macro_f1']:.4f}\")\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(saved_config['model_name'])\n",
    "print(\"✓ Tokenizer loaded!\")\n",
    "\n",
    "# Get optimal threshold (or use default)\n",
    "try:\n",
    "    optimal_threshold = best_threshold\n",
    "    print(f\"\\n✓ Using optimized threshold: {optimal_threshold:.3f}\")\n",
    "except NameError:\n",
    "    optimal_threshold = 0.5\n",
    "    print(f\"\\n⚠ Using default threshold: {optimal_threshold:.3f}\")\n",
    "\n",
    "# Generate predictions\n",
    "predictions, probabilities = generate_predictions(\n",
    "    model=model,\n",
    "    dev_df=dev_df_clean,\n",
    "    tokenizer=tokenizer,\n",
    "    device=device,\n",
    "    threshold=optimal_threshold,\n",
    "    batch_size=saved_config['batch_size'],\n",
    "    use_tta=True,\n",
    "    tta_iterations=saved_config.get('tta_iterations', 5)\n",
    ")\n",
    "\n",
    "# Add to dataframe\n",
    "dev_df_clean['polarization'] = predictions\n",
    "dev_df_clean['confidence'] = probabilities[:, 1]\n",
    "\n",
    "# Statistics\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PREDICTION STATISTICS\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Total: {len(predictions)}\")\n",
    "print(f\"  Class 0 (Non-polarized): {(predictions == 0).sum()} ({(predictions == 0).sum()/len(predictions)*100:.1f}%)\")\n",
    "print(f\"  Class 1 (Polarized):     {(predictions == 1).sum()} ({(predictions == 1).sum()/len(predictions)*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\nPer-language:\")\n",
    "for lang, lang_name in [('en', 'English'), ('es', 'Spanish'), ('de', 'German')]:\n",
    "    lang_mask = dev_df_clean['language'] == lang\n",
    "    lang_preds = predictions[lang_mask]\n",
    "    polarized = (lang_preds == 1).sum()\n",
    "    print(f\"  {lang_name}: {len(lang_preds)} total, {polarized} polarized ({polarized/len(lang_preds)*100:.1f}%)\")\n",
    "\n",
    "# ============================================\n",
    "# SAVE PREDICTIONS\n",
    "# ============================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"SAVING PREDICTIONS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Combined file\n",
    "dev_df_clean[['id', 'text', 'polarization', 'language']].to_csv(\n",
    "    '/kaggle/working/dev_predictions_all.csv', index=False, encoding='utf-8'\n",
    ")\n",
    "print(\"✓ Saved: /kaggle/working/dev_predictions_all.csv\")\n",
    "\n",
    "# Individual language files\n",
    "for lang, original_df, lang_name in [\n",
    "    ('en', eng_dev, 'English'),\n",
    "    ('es', spa_dev, 'Spanish'),\n",
    "    ('de', deu_dev, 'German')\n",
    "]:\n",
    "    lang_predictions = dev_df_clean[dev_df_clean['language'] == lang].copy()\n",
    "    \n",
    "    # Drop the empty polarization column from original if it exists\n",
    "    if 'polarization' in original_df.columns:\n",
    "        original_df = original_df.drop(columns=['polarization'])\n",
    "    \n",
    "    # Merge predictions\n",
    "    original_df_with_preds = original_df.merge(\n",
    "        lang_predictions[['id', 'polarization']],\n",
    "        on='id',\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    # Remove language column if you don't want it\n",
    "    if 'language' in original_df_with_preds.columns:\n",
    "        original_df_with_preds = original_df_with_preds.drop(columns=['language'])\n",
    "    \n",
    "    # Save with only id, text, polarization\n",
    "    original_df_with_preds.to_csv(\n",
    "        f'/kaggle/working/{lang}_dev_predictions.csv',\n",
    "        index=False,\n",
    "        encoding='utf-8'\n",
    "    )\n",
    "    print(f\" Saved: /kaggle/working/{lang}_dev_predictions.csv\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"COMPLETE!\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nOutput files:\")\n",
    "print(\"  1. dev_predictions_all.csv (combined)\")\n",
    "print(\"  2. en_dev_predictions.csv\")\n",
    "print(\"  3. es_dev_predictions.csv\")\n",
    "print(\"  4. de_dev_predictions.csv\")\n",
    "print(\"\\nColumns: id, text, polarization (0/1), confidence, language\")\n",
    "print(\"=\"*70)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 8736564,
     "sourceId": 13731522,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8758204,
     "sourceId": 13762542,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": false,
     "modelId": 504596,
     "modelInstanceId": 489178,
     "sourceId": 648502,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31192,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
