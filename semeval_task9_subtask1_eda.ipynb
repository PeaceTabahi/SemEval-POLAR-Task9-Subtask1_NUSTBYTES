{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "8222c0d3",
      "metadata": {
        "id": "8222c0d3"
      },
      "source": [
        "# Assignment 1: Polarization Detection - EDA\n",
        "## SemEval 2026 Task 9, Subtask 1 (POLAR)\n",
        "### CS-272: Artificial Intelligence"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "19NNklsaKFk0",
        "outputId": "202768d6-8f62-4c06-eb78-62809fe0394b"
      },
      "id": "19NNklsaKFk0",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 1)) (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 2)) (2.0.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 3)) (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 4)) (0.13.2)\n",
            "Requirement already satisfied: wordcloud in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 5)) (1.9.4)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 6)) (3.9.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 7)) (1.6.1)\n",
            "Requirement already satisfied: langdetect in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 8)) (1.0.9)\n",
            "Requirement already satisfied: textblob in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 9)) (0.19.0)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 10)) (5.2.0)\n",
            "Requirement already satisfied: emoji in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 11)) (2.15.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->-r requirements.txt (line 1)) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->-r requirements.txt (line 1)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->-r requirements.txt (line 1)) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r requirements.txt (line 3)) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r requirements.txt (line 3)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r requirements.txt (line 3)) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r requirements.txt (line 3)) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r requirements.txt (line 3)) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r requirements.txt (line 3)) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r requirements.txt (line 3)) (3.2.5)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk->-r requirements.txt (line 6)) (8.3.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk->-r requirements.txt (line 6)) (1.5.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk->-r requirements.txt (line 6)) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk->-r requirements.txt (line 6)) (4.67.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->-r requirements.txt (line 7)) (1.16.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->-r requirements.txt (line 7)) (3.6.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from langdetect->-r requirements.txt (line 8)) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import chardet\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n"
      ],
      "metadata": {
        "id": "qVDSxkOlMlZR",
        "outputId": "79b5acde-4a91-4f7c-9120-366caa6d4c06",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "qVDSxkOlMlZR",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Importing All Needed Libraries and checking the encoding of the Languages **\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**Encoding for english:** Windows-1252\n",
        "**Encoding for spanish:** ascii\n",
        "**Encoding for german:** MacoRoman\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "gwPif1JiN1wv"
      },
      "id": "gwPif1JiN1wv"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "with open(\"spa.csv\", 'rb') as f:\n",
        "    result = chardet.detect(f.read(100000))\n",
        "result\n",
        "# with open(\"spa.csv\", 'rb') as f:   # open in binary mode (b)\n",
        "#     result = chardet.detect(f.read(100000))  # read first 100k bytes\n",
        "# result\n",
        "# with open(\"spa.csv\", 'rb') as f:   # open in binary mode (b)\n",
        "#     result = chardet.detect(f.read(100000))  # read first 100k bytes\n",
        "# result"
      ],
      "metadata": {
        "id": "JnACkwjGKwnQ",
        "outputId": "99c0602f-aa22-4dd5-c5ff-7e4d3a58b0bf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "JnACkwjGKwnQ",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'encoding': 'ascii', 'confidence': 1.0, 'language': ''}"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df_eng = pd.read_csv(\"eng.csv\", encoding=\"Windows-1252\")\n",
        "# Separate English texts by label using 0 and 1\n",
        "polarized_texts = df_eng[df_eng['polarization'] == 1]['text']\n",
        "not_polarized_texts = df_eng[df_eng['polarization'] == 0]['text']\n",
        "\n",
        "# Quick check\n",
        "print(\"Number of polarized texts:\", len(polarized_texts))\n",
        "print(\"Number of not polarized texts:\", len(not_polarized_texts))"
      ],
      "metadata": {
        "id": "7N5ujuRdQ0ZU",
        "outputId": "67ad94a8-6b3e-4f74-a0fc-4fb4a57f6920",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "7N5ujuRdQ0ZU",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of polarized texts: 1002\n",
            "Number of not polarized texts: 1674\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iagehxICRnpA"
      },
      "id": "iagehxICRnpA",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.13.8"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}