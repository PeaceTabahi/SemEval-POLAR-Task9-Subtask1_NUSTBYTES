{
  "model": "XLM-RoBERTa-Large-MacroF1-Optimized",
  "task": "Binary Polarization Detection",
  "configuration": {
    "model_name": "xlm-roberta-large",
    "max_length": 128,
    "batch_size": 8,
    "num_epochs": 15,
    "learning_rate": 2e-06,
    "weight_decay": 0.03,
    "dropout": 0.5,
    "num_dropouts": 5,
    "gradient_accumulation_steps": 4,
    "max_grad_norm": 1.0,
    "warmup_steps": 1000,
    "use_mixup": true,
    "mixup_alpha": 0.2,
    "use_tta": true,
    "tta_iterations": 5,
    "focal_alpha": 0.5,
    "focal_gamma": 2.0,
    "scheduler": "OneCycleLR",
    "scheduler_warmup_pct": 0.10
  },
  "data_info": {
    "train_samples": 7113,
    "val_samples": 791,
    "test_samples": 1832,
    "num_classes": 2,
    "languages": ["English", "Spanish", "German"],
    "augmented_samples": 584,
    "final_balance": "1.016:1 (50.4% vs 49.6%)"
  },
  "training_history": {
    "train_loss": [
      0.0954,
      0.0871,
      0.0809,
      0.0783,
      0.0743,
      0.0740,
      0.0726,
      0.0707,
      0.0703,
      0.0690,
      0.0685,
      0.0681,
      0.0667,
      0.0670
    ],
    "train_macro_f1": [
      0.4904,
      0.5583,
      0.6341,
      0.6475,
      0.6705,
      0.6661,
      0.6737,
      0.6870,
      0.6824,
      0.6866,
      0.6977,
      0.7026,
      0.7073,
      0.7032
    ],
    "val_loss": [
      0.0863,
      0.0743,
      0.0707,
      0.0688,
      0.0687,
      0.0691,
      0.0692,
      0.0713,
      0.0673,
      0.0705,
      0.0692,
      0.0699,
      0.0712,
      0.0711
    ],
    "val_macro_f1": [
      0.3857,
      0.6909,
      0.7158,
      0.7224,
      0.7296,
      0.7455,
      0.7489,
      0.7395,
      0.7520,
      0.7555,
      0.7585,
      0.7532,
      0.7532,
      0.7530
    ],
    "val_weighted_f1": [
      0.3832,
      0.6910,
      0.7160,
      0.7225,
      0.7293,
      0.7456,
      0.7490,
      0.7398,
      0.7522,
      0.7556,
      0.7585,
      0.7532,
      0.7532,
      0.7531
    ],
    "best_epoch": 11,
    "best_val_macro_f1": 0.7585
  },
  "test_results": {
    "accuracy": 0.74617903930131,
    "macro_f1": 0.7444428744866762,
    "weighted_f1": 0.7463055148838331,
    "optimal_threshold": 0.49,
    "precision": 0.7464858669687224,
    "recall": 0.74617903930131,
    "tta_iterations": 5
  },
  "per_language_results": {
    "English": {
      "macro_f1": 0.8047,
      "weighted_f1": 0.8148,
      "accuracy": 0.8131,
      "samples": 535
    },
    "Spanish": {
      "macro_f1": 0.7352,
      "weighted_f1": 0.7352,
      "accuracy": 0.7352,
      "samples": 661
    },
    "German": {
      "macro_f1": 0.7005,
      "weighted_f1": 0.7013,
      "accuracy": 0.7013,
      "samples": 636
    }
  },
  "per_class_f1": {
    "non_polarized": 0.7655068078668683,
    "polarized": 0.7233789411064843
  }
}
